{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![PyPI Shield](https://img.shields.io/pypi/v/wind.svg)](https://pypi.python.org/pypi/wind)\n",
    "[![Travis CI Shield](https://travis-ci.org/D3-AI/wind.svg?branch=master)](https://travis-ci.org/D3-AI/wind)\n",
    "\n",
    "# Wind\n",
    "\n",
    "<p align=\"center\">\n",
    "<i>Machine learning for internet of things related to wind systems.  </I>\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<i>A collaborative open source project between Data to AI Lab at MIT and Xylem Inc. </I>\n",
    "</p>\n",
    "\n",
    "\n",
    "- Free software: MIT license\n",
    "- Documentation: https://D3-AI.github.io/wind\n",
    "- Homepage: https://github.com/D3-AI/wind\n",
    "\n",
    "# Overview\n",
    "\n",
    "The Wind project is a collection of end-to-end solutions for machine learning tasks commonly\n",
    "found in monitoring wind energy production systems. Most tasks utilize sensor data\n",
    "emanating from monitoring systems. We utilize the foundational innovations developed for\n",
    "automation of machine Learning at Data to AI Lab at MIT. This project is developed in close\n",
    "collaboration with Iberdrola, S.A.\n",
    "\n",
    "The salient aspects of this customized project are:\n",
    "* A set of ready to use, well tested pipelines for different machine learning tasks. These are\n",
    "  vetted through testing across multiple publicly available datasets for the same task.\n",
    "* An easy interface to specify the task, pipeline, and generate results and summarize them.\n",
    "* A production ready, deployable pipeline.\n",
    "* An easy interface to ``tune`` pipelines using Bayesian Tuning and Bandits library.\n",
    "* A community oriented infrastructure to incorporate new pipelines.\n",
    "* A robust continuous integration and testing infrastructure.\n",
    "* A ``learning database`` recording all past outcomes --> tasks, pipelines, outcomes.\n",
    "\n",
    "## Concepts\n",
    "\n",
    "Before diving into the software usage, we briefly explain some concepts and terminology.\n",
    "\n",
    "### Primitive\n",
    "\n",
    "We call the smallest computational blocks used in a Machine Learning process\n",
    "**primitives**, which:\n",
    "\n",
    "* Can be either classes or functions.\n",
    "* Have some initialization arguments, which MLBlocks calls `init_params`.\n",
    "* Have some tunable hyperparameters, which have types and a list or range of valid values.\n",
    "\n",
    "### Template\n",
    "\n",
    "Primitives can be combined to form what we call **Templates**, which:\n",
    "\n",
    "* Have a list of primitives.\n",
    "* Have some initialization arguments, which correspond to the initialization arguments\n",
    "  of their primitives.\n",
    "* Have some tunable hyperparameters, which correspond to the tunable hyperparameters\n",
    "  of their primitives.\n",
    "\n",
    "### Pipeline\n",
    "\n",
    "Templates can be used to build **Pipelines** by taking and fixing a set of valid\n",
    "hyperparameters for a Template. Hence, Pipelines:\n",
    "\n",
    "* Have a list of primitives, which corresponds to the list of primitives of their template.\n",
    "* Have some initialization arguments, which correspond to the initialization arguments\n",
    "  of their template.\n",
    "* Have some hyperparameter values, which fall within the ranges of valid tunable\n",
    "  hyperparameters of their template.\n",
    "\n",
    "A pipeline can be fitted and evaluated using the MLPipeline API in MLBlocks.\n",
    "\n",
    "\n",
    "## Current tasks and pipelines\n",
    "\n",
    "In our current phase, we are addressing two tasks - time series classification and time series\n",
    "regression. To provide solutions for these two tasks we have two components.\n",
    "\n",
    "### WindPipeline\n",
    "\n",
    "This class is the one in charge of learning from the data and making predictions by building\n",
    "[MLBlocks](https://hdi-project.github.io/MLBlocks) and later on tuning them using\n",
    "[BTB](https://hdi-project.github.io/BTB/)\n",
    "\n",
    "This class comes in two flavours in the form of subclasses, the **WindClassifier** and the\n",
    "**WindRegressor**, to be used in the corresponding problem types.\n",
    "\n",
    "### WindLoader\n",
    "\n",
    "A class responsible for loading the time series data from CSV files, and return it in the\n",
    "format ready to be used by the **WindPipeline**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind Dataset\n",
    "\n",
    "A dataset is a folder that contains time series data and information about\n",
    "a Machine Learning problem in the form of CSV and JSON files.\n",
    "\n",
    "The expected contents of the `dataset` folder are 4 CSV files:\n",
    "\n",
    "* A **Turbines** table that contains:\n",
    "  * `turbine_id`: column with the unique id of each turbine.\n",
    "  * A number of additional columns with information about each turbine.\n",
    "* A **Signals** table that contains:\n",
    "  * `signal_id`: column with the unique id of each signal.\n",
    "  * A number of additional columns with information about each signal.\n",
    "* A **Readings** table that contains:\n",
    "  * `reading_id`: Unique identifier of this reading.\n",
    "  * `turbine_id`: Unique identifier of the turbine which this reading comes from.\n",
    "  * `signal_id`: Unique identifier of the signal which this reading comes from.\n",
    "  * `timestamp`: Time where the reading took place, as an ISO formatted datetime.\n",
    "  * `value`: Numeric value of this reading.\n",
    "* A **Targets** table that contains:\n",
    "  * `target_id`: Unique identifier of the turbine which this label corresponds to.\n",
    "  * `turbine_id`: Unique identifier of the turbine which this label corresponds to.\n",
    "  * `timestamp`: Time associated with this target\n",
    "  * `target`: The value that we want to predict. This can either be a numerical value or a categorical label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning\n",
    "\n",
    "We call tuning the process of, given a dataset and a template, find the pipeline derived from the\n",
    "given template that gets the best possible score on the given dataset.\n",
    "\n",
    "This process usually involves fitting and evaluating multiple pipelines with different hyperparameter\n",
    "values on the same data while using optimization algorithms to deduce which hyperparameters are more\n",
    "likely to get the best results in the next iterations.\n",
    "\n",
    "We call each one of these tries a **tuning iteration**.\n",
    "\n",
    "\n",
    "# Getting Started\n",
    "\n",
    "## Installation\n",
    "\n",
    "The simplest and recommended way to install **Wind** is using pip:\n",
    "\n",
    "```bash\n",
    "pip install wind\n",
    "```\n",
    "\n",
    "For development, you can also clone the repository and install it from sources\n",
    "\n",
    "```bash\n",
    "git clone git@github.com:D3-AI/wind.git\n",
    "cd wind\n",
    "make install-develop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Example\n",
    "\n",
    "In this example we will load some demo data using the **WindLoader** and fetch it to the\n",
    "**WindPipeline** for it to find the best possible pipeline, fit it using the given data\n",
    "and then make predictions from it.\n",
    "\n",
    "### Load and explore the data\n",
    "\n",
    "We first create a loader instance passing:\n",
    "\n",
    "* The path to the dataset folder\n",
    "* The name of the target table\n",
    "* The name of the target column\n",
    "* Optionally, the names of the readings, turbines and signals tables, in case they are different from the default ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wind.loader import WindLoader\n",
    "\n",
    "loader = WindLoader('../datasets/wind/', 'labels', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we call the `loader.load` method, which will return three elements:\n",
    "\n",
    "* `X`: The contents of the target table, where the training examples can be found, without the target column.\n",
    "* `y`: The target column, as exctracted from the the target table.\n",
    "* `tables`: A dictionary containing the additional tables that the Pipeline will need to run, `readings`, `turbines` and `signals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_id</th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_id  turbine_id  timestamp\n",
       "0         0           0 2013-01-01\n",
       "1         1           0 2013-01-02\n",
       "2         2           0 2013-01-03\n",
       "3         3           0 2013-01-04\n",
       "4         4           0 2013-01-05"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, tables = loader.load()\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['readings', 'signals', 'turbines'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Turbine 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   turbine_id       name\n",
       "0           0  Turbine 0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables['turbines'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>WTG01_Grid Production PossiblePower Avg. (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>WTG02_Grid Production PossiblePower Avg. (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>WTG03_Grid Production PossiblePower Avg. (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>WTG04_Grid Production PossiblePower Avg. (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>WTG05_Grid Production PossiblePower Avg. (5)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id                                          name\n",
       "0          0  WTG01_Grid Production PossiblePower Avg. (1)\n",
       "1          1  WTG02_Grid Production PossiblePower Avg. (2)\n",
       "2          2  WTG03_Grid Production PossiblePower Avg. (3)\n",
       "3          3  WTG04_Grid Production PossiblePower Avg. (4)\n",
       "4          4  WTG05_Grid Production PossiblePower Avg. (5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables['signals'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading_id</th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>signal_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>755.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reading_id  turbine_id  signal_id  timestamp  value\n",
       "0           0           0          0 2013-01-01  817.0\n",
       "1           1           0          1 2013-01-01  805.0\n",
       "2           2           0          2 2013-01-01  786.0\n",
       "3           3           0          3 2013-01-01  809.0\n",
       "4           4           0          4 2013-01-01  755.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables['readings'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "If we want to split the data in train and test subsets, we can do so by splitting the `X` and `y` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best Pipeline\n",
    "\n",
    "Once we have loaded the data, we create a **WindPipeline** instance by passing:\n",
    "\n",
    "* `template (string)`: the name of a template or the path to a template json file.\n",
    "* `metric (string or function)`: The name of the metric to use or a metric function to use.\n",
    "* `cost (bool)`: Whether the metric is a cost function to be minimized or a score to be maximized.\n",
    "\n",
    "Optionally, we can also pass defails about the cross validation configuration:\n",
    "* `stratify`\n",
    "* `cv_splits`\n",
    "* `shuffle`\n",
    "* `random_state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from wind.pipeline import WindPipeline\n",
    "\n",
    "pipeline = WindPipeline('wind_classification', 'accuracy', cv_splits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created the pipeline, we can call its `tune` method to find the best possible\n",
    "hyperparameters for our data, passing the `X`, `y`, and `tables` variables returned by the loader,\n",
    "as well as an indication of the number of tuning iterations that we want to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.tune(X_train, y_train, tables, iterations=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the tuning process has finished, the hyperparameters have been already set in the classifier.\n",
    "\n",
    "We can see the found hyperparameters by calling the `get_hyperparameters` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"pandas.DataFrame.resample#1\": {\n",
      "        \"rule\": \"1D\",\n",
      "        \"time_index\": \"timestamp\",\n",
      "        \"groupby\": [\n",
      "            \"turbine_id\",\n",
      "            \"signal_id\"\n",
      "        ],\n",
      "        \"aggregation\": \"mean\"\n",
      "    },\n",
      "    \"pandas.DataFrame.unstack#1\": {\n",
      "        \"level\": \"signal_id\",\n",
      "        \"reset_index\": true\n",
      "    },\n",
      "    \"featuretools.EntitySet.entity_from_dataframe#1\": {\n",
      "        \"entityset_id\": \"entityset\",\n",
      "        \"entity_id\": \"readings\",\n",
      "        \"index\": \"index\",\n",
      "        \"variable_types\": null,\n",
      "        \"make_index\": true,\n",
      "        \"time_index\": \"timestamp\",\n",
      "        \"secondary_time_index\": null,\n",
      "        \"already_sorted\": false\n",
      "    },\n",
      "    \"featuretools.EntitySet.entity_from_dataframe#2\": {\n",
      "        \"entityset_id\": \"entityset\",\n",
      "        \"entity_id\": \"turbines\",\n",
      "        \"index\": \"turbine_id\",\n",
      "        \"variable_types\": null,\n",
      "        \"make_index\": false,\n",
      "        \"time_index\": null,\n",
      "        \"secondary_time_index\": null,\n",
      "        \"already_sorted\": false\n",
      "    },\n",
      "    \"featuretools.EntitySet.entity_from_dataframe#3\": {\n",
      "        \"entityset_id\": \"entityset\",\n",
      "        \"entity_id\": \"signals\",\n",
      "        \"index\": \"signal_id\",\n",
      "        \"variable_types\": null,\n",
      "        \"make_index\": false,\n",
      "        \"time_index\": null,\n",
      "        \"secondary_time_index\": null,\n",
      "        \"already_sorted\": false\n",
      "    },\n",
      "    \"featuretools.EntitySet.add_relationship#1\": {\n",
      "        \"parent\": \"turbines\",\n",
      "        \"parent_column\": \"turbine_id\",\n",
      "        \"child\": \"readings\",\n",
      "        \"child_column\": \"turbine_id\"\n",
      "    },\n",
      "    \"featuretools.dfs#1\": {\n",
      "        \"target_entity\": \"turbines\",\n",
      "        \"index\": \"turbine_id\",\n",
      "        \"time_index\": \"timestamp\",\n",
      "        \"agg_primitives\": null,\n",
      "        \"trans_primitives\": null,\n",
      "        \"copy\": false,\n",
      "        \"encode\": false,\n",
      "        \"max_depth\": 1,\n",
      "        \"remove_low_information\": true\n",
      "    },\n",
      "    \"mlprimitives.custom.feature_extraction.CategoricalEncoder#1\": {\n",
      "        \"copy\": true,\n",
      "        \"features\": \"auto\",\n",
      "        \"max_labels\": 0\n",
      "    },\n",
      "    \"sklearn.impute.SimpleImputer#1\": {\n",
      "        \"missing_values\": NaN,\n",
      "        \"fill_value\": null,\n",
      "        \"verbose\": false,\n",
      "        \"copy\": true,\n",
      "        \"strategy\": \"mean\"\n",
      "    },\n",
      "    \"sklearn.preprocessing.StandardScaler#1\": {\n",
      "        \"with_mean\": true,\n",
      "        \"with_std\": true\n",
      "    },\n",
      "    \"xgboost.XGBClassifier#1\": {\n",
      "        \"n_jobs\": -1,\n",
      "        \"n_estimators\": 100,\n",
      "        \"max_depth\": 3,\n",
      "        \"learning_rate\": 0.1,\n",
      "        \"gamma\": 0,\n",
      "        \"min_child_weight\": 1\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(pipeline.get_hyperparameters(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as the obtained cross validation score by looking at the `score` attribute of the `tsc` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6592421640188922"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are satisfied with the obtained cross validation score, we can proceed to call\n",
    "the `fit` method passing again the same data elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train, tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we are ready to make predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pipeline.predict(X_test, tables)\n",
    "predictions[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
