{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GreenGuard Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use GreenGuard to:\n",
    "\n",
    "- Load demo data\n",
    "- Find available pipelines and load one as a template\n",
    "- Tune the template arguments to generate the optimal pipeline\n",
    "- Fit the pipeline to our data\n",
    "- Make predictions using the pipeline\n",
    "- Evaluate the goodness-of-fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup the logging\n",
    "\n",
    "This step sets up logging in our environment to increase our visibility over\n",
    "the steps that GreenGuard performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging;\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger().setLevel(level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data\n",
    "\n",
    "The first step is to load the data that we are going to use.\n",
    "\n",
    "In order to use the demo data included in GreenGuard, the `greenguard.demo.load_demo` function can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from greenguard.demo import load_demo\n",
    "\n",
    "target_times, readings = load_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will download some demo data from [GreenGuard S3 demo Bucket](\n",
    "https://d3-ai-greenguard.s3.amazonaws.com/index.html) and load it as\n",
    "the necessary `target_times` and `readings` tables.\n",
    "\n",
    "The exact format of these tables is described in the GreenGuard README and docs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>cutoff_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T001</td>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T001</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T001</td>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T001</td>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T001</td>\n",
       "      <td>2013-01-16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  turbine_id cutoff_time  target\n",
       "0       T001  2013-01-12       0\n",
       "1       T001  2013-01-13       0\n",
       "2       T001  2013-01-14       0\n",
       "3       T001  2013-01-15       1\n",
       "4       T001  2013-01-16       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_times.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "turbine_id             object\n",
       "cutoff_time    datetime64[ns]\n",
       "target                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_times.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>signal_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T001</td>\n",
       "      <td>S01</td>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T001</td>\n",
       "      <td>S02</td>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T001</td>\n",
       "      <td>S03</td>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T001</td>\n",
       "      <td>S04</td>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T001</td>\n",
       "      <td>S05</td>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  turbine_id signal_id  timestamp  value\n",
       "0       T001       S01 2013-01-10  323.0\n",
       "1       T001       S02 2013-01-10  320.0\n",
       "2       T001       S03 2013-01-10  284.0\n",
       "3       T001       S04 2013-01-10  348.0\n",
       "4       T001       S05 2013-01-10  273.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1313540, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "turbine_id            object\n",
       "signal_id             object\n",
       "timestamp     datetime64[ns]\n",
       "value                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readings.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your own Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you want to load your own dataset, all you have to do is load the\n",
    "`target_times` and `readings` tables as `pandas.DataFrame` objects.\n",
    "\n",
    "Make sure to parse the corresponding datetime fields!\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "target_times = pd.read_csv('path/to/your/target_times.csv', parse_dates=['cutoff_time'])\n",
    "readings = pd.read_csv('path/to/your/readings.csv', parse_dates=['timestamp'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data\n",
    "\n",
    "Once we have loaded the `target_times` and before proceeding to training any Machine Learning\n",
    "Pipeline, we will have split them in 2 partitions for training and testing.\n",
    "\n",
    "In this case, we will split them using the [train_test_split function from scikit-learn](\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html),\n",
    "but it can be done with any other suitable tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(target_times, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finding a Template\n",
    "\n",
    "The next step will be to select a template from the ones available in\n",
    "GreenGuard.\n",
    "\n",
    "For this, we can use the `greenguard.get_pipelines` function, which will\n",
    "return us the list of all the available MLBlocks pipelines found in the\n",
    "GreenGuard system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resample_600s_normalize_dfs_1d_xgb_classifier',\n",
       " 'resample_600s_unstack_normalize_dfs_1d_xgb_classifier',\n",
       " 'resample_600s_unstack_double_144_lstm_timeseries_classifier',\n",
       " 'resample_3600s_unstack_24_lstm_timeseries_classifier',\n",
       " 'resample_3600s_unstack_double_24_lstm_timeseries_classifier',\n",
       " 'resample_600s_unstack_dfs_1d_xgb_classifier',\n",
       " 'resample_600s_unstack_144_lstm_timeseries_classifier']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from greenguard import get_pipelines\n",
    "\n",
    "get_pipelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can pass a string to select the pipelines that contain it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resample_600s_normalize_dfs_1d_xgb_classifier',\n",
       " 'resample_600s_unstack_normalize_dfs_1d_xgb_classifier',\n",
       " 'resample_600s_unstack_dfs_1d_xgb_classifier']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pipelines('dfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can pass the keyword `path=True` to obtain a dictionary containing\n",
    "also the path to the pipelines instead of only the list of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'resample_600s_normalize_dfs_1d_xgb_classifier': '/app/greenguard/pipelines/resample_600s_normalize_dfs_1d_xgb_classifier.json',\n",
       " 'resample_600s_unstack_normalize_dfs_1d_xgb_classifier': '/app/greenguard/pipelines/resample_600s_unstack_normalize_dfs_1d_xgb_classifier.json',\n",
       " 'resample_600s_unstack_dfs_1d_xgb_classifier': '/app/greenguard/pipelines/resample_600s_unstack_dfs_1d_xgb_classifier.json'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pipelines('dfs', path=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of this tutorial, we will select and use the pipeline\n",
    "`resample_600s_unstack_normalize_dfs_1d_xgb_classifier` as our template.\n",
    "\n",
    "This templates contains the following steps:\n",
    "\n",
    "- Resample the data using a 10 minute average aggregation\n",
    "- Unstack the data by signal, so each signal is in a different column\n",
    "- Normalize the Turbine IDs into a new table to assist DFS aggregations\n",
    "- Use DFS on the readings based on the target_times cutoff times using a 1d window size\n",
    "- Apply an XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'resample_600s_unstack_normalize_dfs_1d_xgb_classifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finding the best Pipeline\n",
    "\n",
    "Once we have loaded the data, we create a **GreenGuardPipeline** instance by passing:\n",
    "\n",
    "* `template (string)`: the name of a template or the path to a template json file.\n",
    "* `metric (string or function)`: The name of the metric to use or a metric function to use.\n",
    "* `cost (bool)`: Whether the metric is a cost function to be minimized or a score to be maximized.\n",
    "\n",
    "Optionally, we can also pass defails about the cross validation configuration:\n",
    "\n",
    "* `stratify`\n",
    "* `cv_splits`\n",
    "* `shuffle`\n",
    "* `random_state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from greenguard.pipeline import GreenGuardPipeline\n",
    "\n",
    "pipeline = GreenGuardPipeline(template, metric='f1', cv_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created the pipeline, we can call its `tune` method to find the best possible\n",
    "hyperparameters for our data, passing the `target_times` and `readings` variables,\n",
    "as well as an indication of the number of tuning iterations that we want to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:greenguard.pipeline:Scoring the default pipeline\n",
      "INFO:greenguard.pipeline:Running static steps before cross validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 165 features\n",
      "Elapsed: 00:47 | Progress: 100%|██████████\n",
      "Elapsed: 00:24 | Progress: 100%|██████████\n",
      "Built 165 features\n",
      "Elapsed: 00:50 | Progress: 100%|██████████\n",
      "Elapsed: 00:23 | Progress: 100%|██████████\n",
      "Built 165 features\n",
      "Elapsed: 00:46 | Progress: 100%|██████████\n",
      "Elapsed: 00:23 | Progress: 100%|██████████\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:greenguard.pipeline:Default Pipeline score: 0.605187908496732\n",
      "INFO:greenguard.pipeline:Scoring pipeline 1\n",
      "INFO:btb:Using Uniform sampler as user specified r_minimum threshold is not met to start the GP based learning\n",
      "INFO:greenguard.pipeline:Pipeline 1 score: 0.6188131761825791\n",
      "INFO:greenguard.pipeline:Scoring pipeline 2\n",
      "INFO:greenguard.pipeline:Pipeline 2 score: 0.6271095502877767\n",
      "INFO:greenguard.pipeline:Scoring pipeline 3\n",
      "INFO:greenguard.pipeline:Pipeline 3 score: 0.6305597783858653\n",
      "INFO:greenguard.pipeline:Scoring pipeline 4\n",
      "INFO:greenguard.pipeline:Pipeline 4 score: 0.6024864024864024\n",
      "INFO:greenguard.pipeline:Scoring pipeline 5\n",
      "INFO:greenguard.pipeline:Pipeline 5 score: 0.6141217155301661\n"
     ]
    }
   ],
   "source": [
    "pipeline.tune(target_times, readings, iterations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the tuning process has finished, the hyperparameters have been already set in the classifier.\n",
    "\n",
    "We can see the found hyperparameters by calling the `get_hyperparameters` method,\n",
    "which will return a dictionary with the best hyperparameters found so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlprimitives.custom.feature_extraction.CategoricalEncoder#1': {'max_labels': 82},\n",
       " 'xgboost.XGBClassifier#1': {'n_estimators': 785,\n",
       "  'max_depth': 7,\n",
       "  'learning_rate': 0.12220259756122442,\n",
       "  'gamma': 0.07359343182340616,\n",
       "  'min_child_weight': 9}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can  also see the obtained cross validation score by looking at the `cv_score` attribute of the\n",
    "`pipeline` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6305597783858653"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: If the score is not good enough, we can call the `tune` method again as many times\n",
    "as needed and the pipeline will continue its tuning process every time based on the previous\n",
    "results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:greenguard.pipeline:Scoring pipeline 1\n",
      "INFO:greenguard.pipeline:Pipeline 1 score: 0.6635006784260514\n",
      "INFO:greenguard.pipeline:Scoring pipeline 2\n",
      "INFO:greenguard.pipeline:Pipeline 2 score: 0.6845139382452815\n",
      "INFO:greenguard.pipeline:Scoring pipeline 3\n",
      "INFO:greenguard.pipeline:Pipeline 3 score: 0.6424425247954658\n",
      "INFO:greenguard.pipeline:Scoring pipeline 4\n",
      "INFO:greenguard.pipeline:Pipeline 4 score: 0.6146558553876801\n",
      "INFO:greenguard.pipeline:Scoring pipeline 5\n",
      "INFO:greenguard.pipeline:Pipeline 5 score: 0.6188226349516671\n",
      "INFO:greenguard.pipeline:Scoring pipeline 6\n",
      "INFO:greenguard.pipeline:Pipeline 6 score: 0.6213326748609891\n",
      "INFO:greenguard.pipeline:Scoring pipeline 7\n",
      "INFO:greenguard.pipeline:Pipeline 7 score: 0.6431577681577682\n",
      "INFO:greenguard.pipeline:Scoring pipeline 8\n",
      "INFO:greenguard.pipeline:Pipeline 8 score: 0.6119918008302174\n",
      "INFO:greenguard.pipeline:Scoring pipeline 9\n",
      "INFO:greenguard.pipeline:Pipeline 9 score: 0.670814479638009\n",
      "INFO:greenguard.pipeline:Scoring pipeline 10\n",
      "INFO:greenguard.pipeline:Pipeline 10 score: 0.6781385082782808\n"
     ]
    }
   ],
   "source": [
    "pipeline.tune(target_times, readings, iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6845139382452815"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlprimitives.custom.feature_extraction.CategoricalEncoder#1': {'max_labels': 84},\n",
       " 'xgboost.XGBClassifier#1': {'n_estimators': 788,\n",
       "  'max_depth': 4,\n",
       "  'learning_rate': 0.13866846579555614,\n",
       "  'gamma': 0.652732260680545,\n",
       "  'min_child_weight': 10}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fitting the pipeline\n",
    "\n",
    "Once we are satisfied with the obtained cross validation score, we can proceed to call\n",
    "the `fit` method passing again the same data elements.\n",
    "\n",
    "This will fit the pipeline with all the training data available using the best hyperparameters\n",
    "found during the tuning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 165 features\n",
      "Elapsed: 00:52 | Progress: 100%|██████████\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(train, readings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use the fitted pipeline\n",
    "\n",
    "After fitting the pipeline, we are ready to make predictions on new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 00:17 | Progress: 100%|██████████\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline.predict(test, readings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate its prediction performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(test['target'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and load the pipeline\n",
    "\n",
    "Since the tuning and fitting process takes time to execute and requires a lot of data, you\n",
    "will probably want to save a fitted instance and load it later to analyze new signals\n",
    "instead of fitting pipelines over and over again.\n",
    "\n",
    "This can be done by using the `save` and `load` methods from the `GreenGuardPipeline`.\n",
    "\n",
    "In order to save an instance, call its `save` method passing it the path and filename\n",
    "where the model should be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'my_pipeline.pkl'\n",
    "\n",
    "pipeline.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the pipeline is saved, it can be loaded back as a new `GreenGuardPipeline` by using the\n",
    "`GreenGuardPipeline.load` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipeline = GreenGuardPipeline.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once loaded, it can be directly used to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 00:17 | Progress: 100%|██████████\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = new_pipeline.predict(test, readings)\n",
    "predictions[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
