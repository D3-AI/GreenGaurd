{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GreenGuard usage example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use GreenGuard to fit a pipeline and later on use it to make predictions on new data and evaluate the pipeline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging;\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger().setLevel(level=logging.INFO)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data\n",
    "\n",
    "The first step is to load the data that we are going to use.\n",
    "\n",
    "In order to use the demo data included in GreenGuard, the `greenguard.loader.load_demo`\n",
    "can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from greenguard.loader import load_demo\n",
    "\n",
    "X, y, tables = load_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you want to load your own dataset, the `GreenGuardLoader` class can be used.\n",
    "\n",
    "For example, in order to load the data from the folder where we just downloaded the demo data\n",
    "we can use this commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from greenguard.loader import GreenGuardLoader\n",
    "\n",
    "loader = GreenGuardLoader('../greenguard/demo', gzip=True)\n",
    "\n",
    "X, y, tables = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further details about the GreenGuardLoder options please check the corresponding\n",
    "[API Reference page in the docs](https://d3-ai.github.io/GreenGuard/api/greenguard.loader.html#greenguard.loader.GreenGuardLoader)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of either of the previous commands is:\n",
    "\n",
    "* `X`: A pandas.DataFrame with the contents of the\n",
    "  target table.\n",
    "* `y`: A pandas.Series with the contents of\n",
    "  the target column.\n",
    "* `tables`: A dictionary containing the readings, turbines and\n",
    "  signals tables as pandas.DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_id  turbine_id  timestamp\n",
       "0          1           1 2013-01-01\n",
       "1          2           1 2013-01-02\n",
       "2          3           1 2013-01-03\n",
       "3          4           1 2013-01-04\n",
       "4          5           1 2013-01-05"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['readings', 'signals', 'turbines'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reading_id</th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>signal_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>755.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reading_id  turbine_id  signal_id  timestamp  value\n",
       "0           1           1          1 2013-01-01  817.0\n",
       "1           2           1          2 2013-01-01  805.0\n",
       "2           3           1          3 2013-01-01  786.0\n",
       "3           4           1          4 2013-01-01  809.0\n",
       "4           5           1          5 2013-01-01  755.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables['readings'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WTG01_Grid Production PossiblePower Avg. (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WTG02_Grid Production PossiblePower Avg. (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WTG03_Grid Production PossiblePower Avg. (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>WTG04_Grid Production PossiblePower Avg. (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>WTG05_Grid Production PossiblePower Avg. (5)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal_id                                          name\n",
       "0          1  WTG01_Grid Production PossiblePower Avg. (1)\n",
       "1          2  WTG02_Grid Production PossiblePower Avg. (2)\n",
       "2          3  WTG03_Grid Production PossiblePower Avg. (3)\n",
       "3          4  WTG04_Grid Production PossiblePower Avg. (4)\n",
       "4          5  WTG05_Grid Production PossiblePower Avg. (5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables['signals'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Turbine 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   turbine_id       name\n",
       "0           1  Turbine 1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables['turbines'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data\n",
    "\n",
    "If we want to split the data in train and test subsets, we can do so by splitting\n",
    "the X and y variables with any suitable tool.\n",
    "\n",
    "In this case, we will do it using the `train_test_split` function from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finding the best Pipeline\n",
    "\n",
    "Once we have loaded the data, we create a **GreenGuardPipeline** instance by passing:\n",
    "\n",
    "* `template (string)`: the name of a template or the path to a template json file.\n",
    "* `metric (string or function)`: The name of the metric to use or a metric function to use.\n",
    "* `cost (bool)`: Whether the metric is a cost function to be minimized or a score to be maximized.\n",
    "\n",
    "Optionally, we can also pass defails about the cross validation configuration:\n",
    "\n",
    "* `stratify`\n",
    "* `cv_splits`\n",
    "* `shuffle`\n",
    "* `random_state`\n",
    "\n",
    "In this case, we will be loading the `greenguard_classification` pipeline, using\n",
    "the `accuracy` metric, and using only 2 cross validation splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from greenguard.pipeline import GreenGuardPipeline\n",
    "\n",
    "pipeline = GreenGuardPipeline(template='greenguard_classification', metric='accuracy', cv_splits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created the pipeline, we can call its `tune` method to find the best possible\n",
    "hyperparameters for our data, passing the `X`, `y`, and `tables` variables returned by the loader,\n",
    "as well as an indication of the number of tuning iterations that we want to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-18 18:57:09,190 - INFO - pipeline - Scoring the default pipeline\n",
      "2019-04-18 18:59:40,757 - INFO - pipeline - Default Pipeline score: 0.6447509660798626\n",
      "2019-04-18 18:59:40,758 - INFO - pipeline - Scoring pipeline 1\n",
      "2019-04-18 18:59:40,759 - INFO - gp - Using Uniform sampler as user specified r_minimum threshold is not met to start the GP based learning\n",
      "2019-04-18 19:02:26,829 - INFO - pipeline - Pipeline 1 score: 0.659349506225848\n"
     ]
    }
   ],
   "source": [
    "pipeline.tune(X_train, y_train, tables, iterations=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the tuning process has finished, the hyperparameters have been already set in the classifier.\n",
    "\n",
    "We can see the found hyperparameters by calling the `get_hyperparameters` method,\n",
    "which will return a dictionary with the best hyperparameters found so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pandas.DataFrame.resample#1': {'rule': '1D',\n",
       "  'time_index': 'timestamp',\n",
       "  'groupby': ['turbine_id', 'signal_id'],\n",
       "  'aggregation': 'mean'},\n",
       " 'pandas.DataFrame.unstack#1': {'level': 'signal_id', 'reset_index': True},\n",
       " 'featuretools.EntitySet.entity_from_dataframe#1': {'entityset_id': 'entityset',\n",
       "  'entity_id': 'readings',\n",
       "  'index': 'index',\n",
       "  'variable_types': None,\n",
       "  'make_index': True,\n",
       "  'time_index': 'timestamp',\n",
       "  'secondary_time_index': None,\n",
       "  'already_sorted': False},\n",
       " 'featuretools.EntitySet.entity_from_dataframe#2': {'entityset_id': 'entityset',\n",
       "  'entity_id': 'turbines',\n",
       "  'index': 'turbine_id',\n",
       "  'variable_types': None,\n",
       "  'make_index': False,\n",
       "  'time_index': None,\n",
       "  'secondary_time_index': None,\n",
       "  'already_sorted': False},\n",
       " 'featuretools.EntitySet.entity_from_dataframe#3': {'entityset_id': 'entityset',\n",
       "  'entity_id': 'signals',\n",
       "  'index': 'signal_id',\n",
       "  'variable_types': None,\n",
       "  'make_index': False,\n",
       "  'time_index': None,\n",
       "  'secondary_time_index': None,\n",
       "  'already_sorted': False},\n",
       " 'featuretools.EntitySet.add_relationship#1': {'parent': 'turbines',\n",
       "  'parent_column': 'turbine_id',\n",
       "  'child': 'readings',\n",
       "  'child_column': 'turbine_id'},\n",
       " 'featuretools.dfs#1': {'target_entity': 'turbines',\n",
       "  'index': 'turbine_id',\n",
       "  'time_index': 'timestamp',\n",
       "  'agg_primitives': None,\n",
       "  'trans_primitives': None,\n",
       "  'copy': False,\n",
       "  'encode': False,\n",
       "  'max_depth': 3,\n",
       "  'remove_low_information': True},\n",
       " 'mlprimitives.custom.feature_extraction.CategoricalEncoder#1': {'copy': True,\n",
       "  'features': 'auto',\n",
       "  'max_labels': 23},\n",
       " 'sklearn.impute.SimpleImputer#1': {'missing_values': nan,\n",
       "  'fill_value': None,\n",
       "  'verbose': False,\n",
       "  'copy': True,\n",
       "  'strategy': 'constant'},\n",
       " 'sklearn.preprocessing.StandardScaler#1': {'with_mean': True,\n",
       "  'with_std': False},\n",
       " 'xgboost.XGBClassifier#1': {'n_jobs': -1,\n",
       "  'n_estimators': 353,\n",
       "  'max_depth': 4,\n",
       "  'learning_rate': 0.6150792206840879,\n",
       "  'gamma': 0.46831924909241274,\n",
       "  'min_child_weight': 3}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can  also see the obtained cross validation score by looking at the `score` attribute of the\n",
    "`pipeline` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.659349506225848"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: If the score is not good enough, we can call the `tune` method again as many times\n",
    "as needed and the pipeline will continue its tuning process every time based on the previous\n",
    "results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fitting the pipeline\n",
    "\n",
    "Once we are satisfied with the obtained cross validation score, we can proceed to call\n",
    "the `fit` method passing again the same data elements.\n",
    "\n",
    "This will fit the pipeline with all the training data available using the best hyperparameters\n",
    "found during the tuning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train, tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use the fitted pipeline\n",
    "\n",
    "After fitting the pipeline, we are ready to make predictions on new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test, tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate its prediction performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6413043478260869"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and load the pipeline\n",
    "\n",
    "Since the tuning and fitting process takes time to execute and requires a lot of data, you\n",
    "will probably want to save a fitted instance and load it later to analyze new signals\n",
    "instead of fitting pipelines over and over again.\n",
    "\n",
    "This can be done by using the `save` and `load` methods from the `GreenGuardPipeline`.\n",
    "\n",
    "In order to save an instance, call its `save` method passing it the path and filename\n",
    "where the model should be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'my_pipeline.pkl'\n",
    "\n",
    "pipeline.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the pipeline is saved, it can be loaded back as a new `GreenGuardPipeline` by using the\n",
    "`GreenGuardPipeline.load` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipeline = GreenGuardPipeline.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once loaded, it can be directly used to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = new_pipeline.predict(X_test, tables)\n",
    "predictions[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
